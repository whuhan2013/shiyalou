<!DOCTYPE html>
<!-- saved from url=(0056)https://www.shiyanlou.com/courses/707/labs/2300/document -->
<html lang="zh-CN"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><style class="vjs-styles-defaults">
      .video-js {
        width: 300px;
        height: 150px;
      }

      .vjs-fluid {
        padding-top: 56.25%
      }
    </style>
	
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="author" content="Lei Shi">
    <meta http-equiv="Cache-Control" content="o-transform">
    <meta http-equiv="Cache-Control" content="no-siteapp">
	
		
        <title>无监督学习进行人脸数据降维 - 实验楼</title>
		
	

    
    <meta content="实验楼是国内领先的IT技术实训平台，创新的实验驱动教学模式，以就业为导向，为IT相关专业的在校学生及从业者提供编程、运维、测试、云计算、大数据、数据库等全面的IT技术动手实践环境，提供Linux、Python、Java、C语言、Ruby、Android、IOS开发等热门课程。" name="description">
    <meta content="实验楼,IT培训,IT教育,编程,在线编程,Linux,Linux教程,Linux操作系统,Python,Python教程,Python基础教程,Java,Java编程,C语言,大数据,Node.js,Hadoop,PHP,Docker" name="keywords">
    
    <meta content="实验楼,琛石科技" name="author">

	<link rel="shortcut icon" href="https://static.shiyanlou.com/favicon.ico">
	<link rel="stylesheet" href="./无监督学习进行人脸数据降维 - 实验楼_files/font-awesome.min.css">
    <link rel="stylesheet" href="./无监督学习进行人脸数据降维 - 实验楼_files/monokai-sublime.min.css">
    <link rel="stylesheet" href="./无监督学习进行人脸数据降维 - 实验楼_files/bootstrap.min.css">
    <link rel="stylesheet" href="./无监督学习进行人脸数据降维 - 实验楼_files/katex.min.css">
    <link rel="stylesheet" href="./无监督学习进行人脸数据降维 - 实验楼_files/video-js.min.css">
	<link rel="stylesheet" href="./无监督学习进行人脸数据降维 - 实验楼_files/styles.css">

	<style>
		@font-face {
			font-family: "lantingxihei";
			src: url("https://static.shiyanlou.com/fonts/FZLTCXHJW.TTF");
		}

        /* modal 模态框*/
        #invite-user .modal-body {
            overflow: hidden;
        }
		#invite-user .modal-body .form-label {
			margin-bottom: 16px;
			font-size:14px;
		}
		#invite-user .modal-body .form-invite {
			width: 80%;
			padding: 6px 12px;
			background-color: #eeeeee;
			border: 1px solid #cccccc;
			border-radius: 5px;
			float: left;
			margin-right: 10px;
		}
		#invite-user .modal-body .msg-modal-style {
			background-color: #7dd383;
			margin-top: 10px;
			padding: 6px 0;
			text-align: center;
			width: 100%;
		}
		#invite-user .modal-body .modal-flash {
			position: absolute;
			top: 53px;
			right: 74px;
			z-index: 999;
		}
		/* end modal */

        .en-footer {
            padding: 30px;
            text-align: center;
            font-size: 14px;
        }
    </style>
	
<style>
    #editor {
        width: 0;
		height: 0;
		margin: 0;
		padding: 0;
		border: none;
    }
    #preview {
        padding: 20px;
        background: #fff;
        border: solid 1px #eee;
    }
	#preview p,
	#preview li,
	#preview span,
	#preview div,
	#preview blockquote,
	#preview blockquote	p {
		font-size: 15px;
        font-weight: 100;
	}
	#preview blockquote p {
		line-height: 1.6em;
	}
    .mobile-alert {
        display: none;
        margin-top: 10px;
        font-size: 16px;
        text-align: center;
    }
    .breadcrumb {
        border-bottom: solid 1px #eee;
    }
    @media (max-width: 768px) {
        .mobile-alert {
            display: block;
        }
        #preview p,
        #preview li,
        #preview span,
        #preview div,
        #preview blockquote,
        #preview blockquote	p {
            font-weight: 500;
        }
    }
    .start-lab {
        position: fixed;
        bottom: 0;
        left: 0;
        width: 100%;
        padding: 10px 0;
        text-align: center;
        box-shadow: 0 2px 4px 2px #eee;
        background: #274a59;
        z-index: 100;
    }
    .start-lab span {
        position: relative;
        top: 4px;
        color: #fff;
        font-size: 16px;
    }
    .start-lab .btn {
        margin-left: 10px;
        padding: 6px 50px;
        background: #0c9;
        font-size: 18px;
        border-color: #0c9;
    }
    @media (max-width: 768px) {
        .start-lab .btn {
            margin-top: 10px;
        }
    }
    .course-warning {
        margin-top: 10px;
        text-align: center;
        font-size: 16px;
    }
    .course-warning a {
        padding: 6px 50px;
        font-size: 16px;
    }

    .info-panel {
        position: relative;
        top: 0;
        background: cornsilk;
    }
    .info-panel div {
        margin-bottom: 10px;
        font-size: 16px;
    }
    .info-panel .btn {
        margin-top: 10px;
        border-radius: 4px;
    }
    
</style>


	
    
<style id="ace_editor.css">.ace_editor {position: relative;overflow: hidden;font: 12px/normal 'Monaco', 'Menlo', 'Ubuntu Mono', 'Consolas', 'source-code-pro', monospace;direction: ltr;text-align: left;}.ace_scroller {position: absolute;overflow: hidden;top: 0;bottom: 0;background-color: inherit;-ms-user-select: none;-moz-user-select: none;-webkit-user-select: none;user-select: none;cursor: text;}.ace_content {position: absolute;-moz-box-sizing: border-box;-webkit-box-sizing: border-box;box-sizing: border-box;min-width: 100%;}.ace_dragging .ace_scroller:before{position: absolute;top: 0;left: 0;right: 0;bottom: 0;content: '';background: rgba(250, 250, 250, 0.01);z-index: 1000;}.ace_dragging.ace_dark .ace_scroller:before{background: rgba(0, 0, 0, 0.01);}.ace_selecting, .ace_selecting * {cursor: text !important;}.ace_gutter {position: absolute;overflow : hidden;width: auto;top: 0;bottom: 0;left: 0;cursor: default;z-index: 4;-ms-user-select: none;-moz-user-select: none;-webkit-user-select: none;user-select: none;}.ace_gutter-active-line {position: absolute;left: 0;right: 0;}.ace_scroller.ace_scroll-left {box-shadow: 17px 0 16px -16px rgba(0, 0, 0, 0.4) inset;}.ace_gutter-cell {padding-left: 19px;padding-right: 6px;background-repeat: no-repeat;}.ace_gutter-cell.ace_error {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAABOFBMVEX/////////QRswFAb/Ui4wFAYwFAYwFAaWGAfDRymzOSH/PxswFAb/SiUwFAYwFAbUPRvjQiDllog5HhHdRybsTi3/Tyv9Tir+Syj/UC3////XurebMBIwFAb/RSHbPx/gUzfdwL3kzMivKBAwFAbbvbnhPx66NhowFAYwFAaZJg8wFAaxKBDZurf/RB6mMxb/SCMwFAYwFAbxQB3+RB4wFAb/Qhy4Oh+4QifbNRcwFAYwFAYwFAb/QRzdNhgwFAYwFAbav7v/Uy7oaE68MBK5LxLewr/r2NXewLswFAaxJw4wFAbkPRy2PyYwFAaxKhLm1tMwFAazPiQwFAaUGAb/QBrfOx3bvrv/VC/maE4wFAbRPBq6MRO8Qynew8Dp2tjfwb0wFAbx6eju5+by6uns4uH9/f36+vr/GkHjAAAAYnRSTlMAGt+64rnWu/bo8eAA4InH3+DwoN7j4eLi4xP99Nfg4+b+/u9B/eDs1MD1mO7+4PHg2MXa347g7vDizMLN4eG+Pv7i5evs/v79yu7S3/DV7/498Yv24eH+4ufQ3Ozu/v7+y13sRqwAAADLSURBVHjaZc/XDsFgGIBhtDrshlitmk2IrbHFqL2pvXf/+78DPokj7+Fz9qpU/9UXJIlhmPaTaQ6QPaz0mm+5gwkgovcV6GZzd5JtCQwgsxoHOvJO15kleRLAnMgHFIESUEPmawB9ngmelTtipwwfASilxOLyiV5UVUyVAfbG0cCPHig+GBkzAENHS0AstVF6bacZIOzgLmxsHbt2OecNgJC83JERmePUYq8ARGkJx6XtFsdddBQgZE2nPR6CICZhawjA4Fb/chv+399kfR+MMMDGOQAAAABJRU5ErkJggg==");background-repeat: no-repeat;background-position: 2px center;}.ace_gutter-cell.ace_warning {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAAmVBMVEX///8AAAD///8AAAAAAABPSzb/5sAAAAB/blH/73z/ulkAAAAAAAD85pkAAAAAAAACAgP/vGz/rkDerGbGrV7/pkQICAf////e0IsAAAD/oED/qTvhrnUAAAD/yHD/njcAAADuv2r/nz//oTj/p064oGf/zHAAAAA9Nir/tFIAAAD/tlTiuWf/tkIAAACynXEAAAAAAAAtIRW7zBpBAAAAM3RSTlMAABR1m7RXO8Ln31Z36zT+neXe5OzooRDfn+TZ4p3h2hTf4t3k3ucyrN1K5+Xaks52Sfs9CXgrAAAAjklEQVR42o3PbQ+CIBQFYEwboPhSYgoYunIqqLn6/z8uYdH8Vmdnu9vz4WwXgN/xTPRD2+sgOcZjsge/whXZgUaYYvT8QnuJaUrjrHUQreGczuEafQCO/SJTufTbroWsPgsllVhq3wJEk2jUSzX3CUEDJC84707djRc5MTAQxoLgupWRwW6UB5fS++NV8AbOZgnsC7BpEAAAAABJRU5ErkJggg==");background-position: 2px center;}.ace_gutter-cell.ace_info {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAAAAAA6mKC9AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAJ0Uk5TAAB2k804AAAAPklEQVQY02NgIB68QuO3tiLznjAwpKTgNyDbMegwisCHZUETUZV0ZqOquBpXj2rtnpSJT1AEnnRmL2OgGgAAIKkRQap2htgAAAAASUVORK5CYII=");background-position: 2px center;}.ace_dark .ace_gutter-cell.ace_info {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQBAMAAADt3eJSAAAAJFBMVEUAAAChoaGAgIAqKiq+vr6tra1ZWVmUlJSbm5s8PDxubm56enrdgzg3AAAAAXRSTlMAQObYZgAAAClJREFUeNpjYMAPdsMYHegyJZFQBlsUlMFVCWUYKkAZMxZAGdxlDMQBAG+TBP4B6RyJAAAAAElFTkSuQmCC");}.ace_scrollbar {position: absolute;right: 0;bottom: 0;z-index: 6;}.ace_scrollbar-inner {position: absolute;cursor: text;left: 0;top: 0;}.ace_scrollbar-v{overflow-x: hidden;overflow-y: scroll;top: 0;}.ace_scrollbar-h {overflow-x: scroll;overflow-y: hidden;left: 0;}.ace_print-margin {position: absolute;height: 100%;}.ace_text-input {position: absolute;z-index: 0;width: 0.5em;height: 1em;opacity: 0;background: transparent;-moz-appearance: none;appearance: none;border: none;resize: none;outline: none;overflow: hidden;font: inherit;padding: 0 1px;margin: 0 -1px;text-indent: -1em;-ms-user-select: text;-moz-user-select: text;-webkit-user-select: text;user-select: text;white-space: pre!important;}.ace_text-input.ace_composition {background: inherit;color: inherit;z-index: 1000;opacity: 1;text-indent: 0;}.ace_layer {z-index: 1;position: absolute;overflow: hidden;word-wrap: normal;white-space: pre;height: 100%;width: 100%;-moz-box-sizing: border-box;-webkit-box-sizing: border-box;box-sizing: border-box;pointer-events: none;}.ace_gutter-layer {position: relative;width: auto;text-align: right;pointer-events: auto;}.ace_text-layer {font: inherit !important;}.ace_cjk {display: inline-block;text-align: center;}.ace_cursor-layer {z-index: 4;}.ace_cursor {z-index: 4;position: absolute;-moz-box-sizing: border-box;-webkit-box-sizing: border-box;box-sizing: border-box;border-left: 2px solid;transform: translatez(0);}.ace_slim-cursors .ace_cursor {border-left-width: 1px;}.ace_overwrite-cursors .ace_cursor {border-left-width: 0;border-bottom: 1px solid;}.ace_hidden-cursors .ace_cursor {opacity: 0.2;}.ace_smooth-blinking .ace_cursor {-webkit-transition: opacity 0.18s;transition: opacity 0.18s;}.ace_editor.ace_multiselect .ace_cursor {border-left-width: 1px;}.ace_marker-layer .ace_step, .ace_marker-layer .ace_stack {position: absolute;z-index: 3;}.ace_marker-layer .ace_selection {position: absolute;z-index: 5;}.ace_marker-layer .ace_bracket {position: absolute;z-index: 6;}.ace_marker-layer .ace_active-line {position: absolute;z-index: 2;}.ace_marker-layer .ace_selected-word {position: absolute;z-index: 4;-moz-box-sizing: border-box;-webkit-box-sizing: border-box;box-sizing: border-box;}.ace_line .ace_fold {-moz-box-sizing: border-box;-webkit-box-sizing: border-box;box-sizing: border-box;display: inline-block;height: 11px;margin-top: -2px;vertical-align: middle;background-image:url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABEAAAAJCAYAAADU6McMAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAJpJREFUeNpi/P//PwOlgAXGYGRklAVSokD8GmjwY1wasKljQpYACtpCFeADcHVQfQyMQAwzwAZI3wJKvCLkfKBaMSClBlR7BOQikCFGQEErIH0VqkabiGCAqwUadAzZJRxQr/0gwiXIal8zQQPnNVTgJ1TdawL0T5gBIP1MUJNhBv2HKoQHHjqNrA4WO4zY0glyNKLT2KIfIMAAQsdgGiXvgnYAAAAASUVORK5CYII="),url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAA3CAYAAADNNiA5AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAACJJREFUeNpi+P//fxgTAwPDBxDxD078RSX+YeEyDFMCIMAAI3INmXiwf2YAAAAASUVORK5CYII=");background-repeat: no-repeat, repeat-x;background-position: center center, top left;color: transparent;border: 1px solid black;border-radius: 2px;cursor: pointer;pointer-events: auto;}.ace_dark .ace_fold {}.ace_fold:hover{background-image:url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABEAAAAJCAYAAADU6McMAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAJpJREFUeNpi/P//PwOlgAXGYGRklAVSokD8GmjwY1wasKljQpYACtpCFeADcHVQfQyMQAwzwAZI3wJKvCLkfKBaMSClBlR7BOQikCFGQEErIH0VqkabiGCAqwUadAzZJRxQr/0gwiXIal8zQQPnNVTgJ1TdawL0T5gBIP1MUJNhBv2HKoQHHjqNrA4WO4zY0glyNKLT2KIfIMAAQsdgGiXvgnYAAAAASUVORK5CYII="),url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAA3CAYAAADNNiA5AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAACBJREFUeNpi+P//fz4TAwPDZxDxD5X4i5fLMEwJgAADAEPVDbjNw87ZAAAAAElFTkSuQmCC");}.ace_tooltip {background-color: #FFF;background-image: -webkit-linear-gradient(top, transparent, rgba(0, 0, 0, 0.1));background-image: linear-gradient(to bottom, transparent, rgba(0, 0, 0, 0.1));border: 1px solid gray;border-radius: 1px;box-shadow: 0 1px 2px rgba(0, 0, 0, 0.3);color: black;max-width: 100%;padding: 3px 4px;position: fixed;z-index: 999999;-moz-box-sizing: border-box;-webkit-box-sizing: border-box;box-sizing: border-box;cursor: default;white-space: pre;word-wrap: break-word;line-height: normal;font-style: normal;font-weight: normal;letter-spacing: normal;pointer-events: none;}.ace_folding-enabled > .ace_gutter-cell {padding-right: 13px;}.ace_fold-widget {-moz-box-sizing: border-box;-webkit-box-sizing: border-box;box-sizing: border-box;margin: 0 -12px 0 1px;display: none;width: 11px;vertical-align: top;background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAANElEQVR42mWKsQ0AMAzC8ixLlrzQjzmBiEjp0A6WwBCSPgKAXoLkqSot7nN3yMwR7pZ32NzpKkVoDBUxKAAAAABJRU5ErkJggg==");background-repeat: no-repeat;background-position: center;border-radius: 3px;border: 1px solid transparent;cursor: pointer;}.ace_folding-enabled .ace_fold-widget {display: inline-block;   }.ace_fold-widget.ace_end {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAANElEQVR42m3HwQkAMAhD0YzsRchFKI7sAikeWkrxwScEB0nh5e7KTPWimZki4tYfVbX+MNl4pyZXejUO1QAAAABJRU5ErkJggg==");}.ace_fold-widget.ace_closed {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAMAAAAGCAYAAAAG5SQMAAAAOUlEQVR42jXKwQkAMAgDwKwqKD4EwQ26sSOkVWjgIIHAzPiCgaqiqnJHZnKICBERHN194O5b9vbLuAVRL+l0YWnZAAAAAElFTkSuQmCCXA==");}.ace_fold-widget:hover {border: 1px solid rgba(0, 0, 0, 0.3);background-color: rgba(255, 255, 255, 0.2);box-shadow: 0 1px 1px rgba(255, 255, 255, 0.7);}.ace_fold-widget:active {border: 1px solid rgba(0, 0, 0, 0.4);background-color: rgba(0, 0, 0, 0.05);box-shadow: 0 1px 1px rgba(255, 255, 255, 0.8);}.ace_dark .ace_fold-widget {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAAHklEQVQIW2P4//8/AzoGEQ7oGCaLLAhWiSwB146BAQCSTPYocqT0AAAAAElFTkSuQmCC");}.ace_dark .ace_fold-widget.ace_end {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAAH0lEQVQIW2P4//8/AxQ7wNjIAjDMgC4AxjCVKBirIAAF0kz2rlhxpAAAAABJRU5ErkJggg==");}.ace_dark .ace_fold-widget.ace_closed {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAMAAAAFCAYAAACAcVaiAAAAHElEQVQIW2P4//+/AxAzgDADlOOAznHAKgPWAwARji8UIDTfQQAAAABJRU5ErkJggg==");}.ace_dark .ace_fold-widget:hover {box-shadow: 0 1px 1px rgba(255, 255, 255, 0.2);background-color: rgba(255, 255, 255, 0.1);}.ace_dark .ace_fold-widget:active {box-shadow: 0 1px 1px rgba(255, 255, 255, 0.2);}.ace_fold-widget.ace_invalid {background-color: #FFB4B4;border-color: #DE5555;}.ace_fade-fold-widgets .ace_fold-widget {-webkit-transition: opacity 0.4s ease 0.05s;transition: opacity 0.4s ease 0.05s;opacity: 0;}.ace_fade-fold-widgets:hover .ace_fold-widget {-webkit-transition: opacity 0.05s ease 0.05s;transition: opacity 0.05s ease 0.05s;opacity:1;}.ace_underline {text-decoration: underline;}.ace_bold {font-weight: bold;}.ace_nobold .ace_bold {font-weight: normal;}.ace_italic {font-style: italic;}.ace_error-marker {background-color: rgba(255, 0, 0,0.2);position: absolute;z-index: 9;}.ace_highlight-marker {background-color: rgba(255, 255, 0,0.2);position: absolute;z-index: 8;}.ace_br1 {border-top-left-radius    : 3px;}.ace_br2 {border-top-right-radius   : 3px;}.ace_br3 {border-top-left-radius    : 3px; border-top-right-radius:    3px;}.ace_br4 {border-bottom-right-radius: 3px;}.ace_br5 {border-top-left-radius    : 3px; border-bottom-right-radius: 3px;}.ace_br6 {border-top-right-radius   : 3px; border-bottom-right-radius: 3px;}.ace_br7 {border-top-left-radius    : 3px; border-top-right-radius:    3px; border-bottom-right-radius: 3px;}.ace_br8 {border-bottom-left-radius : 3px;}.ace_br9 {border-top-left-radius    : 3px; border-bottom-left-radius:  3px;}.ace_br10{border-top-right-radius   : 3px; border-bottom-left-radius:  3px;}.ace_br11{border-top-left-radius    : 3px; border-top-right-radius:    3px; border-bottom-left-radius:  3px;}.ace_br12{border-bottom-right-radius: 3px; border-bottom-left-radius:  3px;}.ace_br13{border-top-left-radius    : 3px; border-bottom-right-radius: 3px; border-bottom-left-radius:  3px;}.ace_br14{border-top-right-radius   : 3px; border-bottom-right-radius: 3px; border-bottom-left-radius:  3px;}.ace_br15{border-top-left-radius    : 3px; border-top-right-radius:    3px; border-bottom-right-radius: 3px; border-bottom-left-radius: 3px;}
/*# sourceURL=ace/css/ace_editor.css */</style><style id="ace-tm">.ace-tm .ace_gutter {background: #f0f0f0;color: #333;}.ace-tm .ace_print-margin {width: 1px;background: #e8e8e8;}.ace-tm .ace_fold {background-color: #6B72E6;}.ace-tm {background-color: #FFFFFF;color: black;}.ace-tm .ace_cursor {color: black;}.ace-tm .ace_invisible {color: rgb(191, 191, 191);}.ace-tm .ace_storage,.ace-tm .ace_keyword {color: blue;}.ace-tm .ace_constant {color: rgb(197, 6, 11);}.ace-tm .ace_constant.ace_buildin {color: rgb(88, 72, 246);}.ace-tm .ace_constant.ace_language {color: rgb(88, 92, 246);}.ace-tm .ace_constant.ace_library {color: rgb(6, 150, 14);}.ace-tm .ace_invalid {background-color: rgba(255, 0, 0, 0.1);color: red;}.ace-tm .ace_support.ace_function {color: rgb(60, 76, 114);}.ace-tm .ace_support.ace_constant {color: rgb(6, 150, 14);}.ace-tm .ace_support.ace_type,.ace-tm .ace_support.ace_class {color: rgb(109, 121, 222);}.ace-tm .ace_keyword.ace_operator {color: rgb(104, 118, 135);}.ace-tm .ace_string {color: rgb(3, 106, 7);}.ace-tm .ace_comment {color: rgb(76, 136, 107);}.ace-tm .ace_comment.ace_doc {color: rgb(0, 102, 255);}.ace-tm .ace_comment.ace_doc.ace_tag {color: rgb(128, 159, 191);}.ace-tm .ace_constant.ace_numeric {color: rgb(0, 0, 205);}.ace-tm .ace_variable {color: rgb(49, 132, 149);}.ace-tm .ace_xml-pe {color: rgb(104, 104, 91);}.ace-tm .ace_entity.ace_name.ace_function {color: #0000A2;}.ace-tm .ace_heading {color: rgb(12, 7, 255);}.ace-tm .ace_list {color:rgb(185, 6, 144);}.ace-tm .ace_meta.ace_tag {color:rgb(0, 22, 142);}.ace-tm .ace_string.ace_regex {color: rgb(255, 0, 0)}.ace-tm .ace_marker-layer .ace_selection {background: rgb(181, 213, 255);}.ace-tm.ace_multiselect .ace_selection.ace_start {box-shadow: 0 0 3px 0px white;}.ace-tm .ace_marker-layer .ace_step {background: rgb(252, 255, 0);}.ace-tm .ace_marker-layer .ace_stack {background: rgb(164, 229, 101);}.ace-tm .ace_marker-layer .ace_bracket {margin: -1px 0 0 -1px;border: 1px solid rgb(192, 192, 192);}.ace-tm .ace_marker-layer .ace_active-line {background: rgba(0, 0, 0, 0.07);}.ace-tm .ace_gutter-active-line {background-color : #dcdcdc;}.ace-tm .ace_marker-layer .ace_selected-word {background: rgb(250, 250, 255);border: 1px solid rgb(200, 200, 250);}.ace-tm .ace_indent-guide {background: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAACCAYAAACZgbYnAAAAE0lEQVQImWP4////f4bLly//BwAmVgd1/w11/gAAAABJRU5ErkJggg==") right repeat-y;}
/*# sourceURL=ace/css/ace-tm */</style><style>    .error_widget_wrapper {        background: inherit;        color: inherit;        border:none    }    .error_widget {        border-top: solid 2px;        border-bottom: solid 2px;        margin: 5px 0;        padding: 10px 40px;        white-space: pre-wrap;    }    .error_widget.ace_error, .error_widget_arrow.ace_error{        border-color: #ff5a5a    }    .error_widget.ace_warning, .error_widget_arrow.ace_warning{        border-color: #F1D817    }    .error_widget.ace_info, .error_widget_arrow.ace_info{        border-color: #5a5a5a    }    .error_widget.ace_ok, .error_widget_arrow.ace_ok{        border-color: #5aaa5a    }    .error_widget_arrow {        position: absolute;        border: solid 5px;        border-top-color: transparent!important;        border-right-color: transparent!important;        border-left-color: transparent!important;        top: -5px;    }</style></head>

<body>
	
        
        
            






<nav class="navbar navbar-default navbar-fixed-top header">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#header-navbar-collapse" aria-expanded="false">
                <span class="sr-only">实验楼</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://www.shiyanlou.com/">
                <img src="./无监督学习进行人脸数据降维 - 实验楼_files/logo_03.png">
            </a>
        </div>
        <div class="collapse navbar-collapse" id="header-navbar-collapse">
            <ul class="nav navbar-nav">
                <li class="dropdown active">
                    <a href="javascript:void(0);" class="dropdown-toggle" data-toggle="dropdown">
                        课程
                        <span class="caret"></span>
                    </a>
                    <ul class="dropdown-menu">
                        <li><a class="" href="https://www.shiyanlou.com/courses/">全部课程</a></li>
                        <li><a class="" href="https://www.shiyanlou.com/courses/?status=preview">即将上线</a></li>
                        <li><a class="" href="https://www.shiyanlou.com/developer">开发者</a></li>
                    </ul>
                </li>
                <li class="">
                    <a href="https://www.shiyanlou.com/paths/">路径</a>
                </li>
                <li class="">
                    <a href="https://www.shiyanlou.com/questions/">讨论区</a>
                </li>
                <li class=" bootcamp new-nav logo-1111">
                    <a href="https://www.shiyanlou.com/bootcamp/">训练营</a>
                    
                </li>
                <li class=" new-nav logo-1111">
                    <a href="https://www.shiyanlou.com/vip">会员</a>
                    
                </li>
                
					
					<li class=""><a href="https://www.shiyanlou.com/user/235723">我的课程</a></li>
					
                
            </ul>

            
            <ul class="nav navbar-nav navbar-right user">
                
                <li class="dropdown">
                    <a href="https://www.shiyanlou.com/user/235723" class="dropdown-toggle hidden-xs">
                        <img class="header-avatar" src="./无监督学习进行人脸数据降维 - 实验楼_files/gravatarHA954FKT7YJW.jpg" data-toggle="tooltip" data-placement="bottom" data-trigger="manual" title="" data-template="&lt;div class=&quot;tooltip&quot; data-url=&quot;/user/235723/messages&quot; role=&quot;tooltip&quot;&gt;&lt;div class=&quot;tooltip-arrow&quot; style=&quot;border-bottom-color:#f66e6e;&quot;&gt;&lt;/div&gt;&lt;div class=&quot;tooltip-inner&quot; style=&quot;background:#f66e6e;&quot;&gt;&lt;/div&gt;&lt;/div&gt;" data-original-title="新消息">
                        
                        <span class="header-msg-count" style="display:none;"></span>
                        
    
    
    
    <div class="user-username ">
        <span class="username" href="/user/235723" target="_blank">
            whuhan2013
        </span>
        <span class="user-level">L1</span>
    </div>

                        <span class="caret"></span>
                    </a>
					<a href="https://www.shiyanlou.com/courses/707/labs/2300/document#" class="dropdown-toggle visible-xs-block" data-toggle="dropdown">
                        <img class="header-avatar" src="./无监督学习进行人脸数据降维 - 实验楼_files/gravatarHA954FKT7YJW.jpg">
                        
                        <span class="header-msg-count" style="display:none;"></span>
                        <span class="header-username">whuhan2013</span>
                        <span class="caret"></span>
                    </a>
                    <ul class="dropdown-menu">
                        <li><a href="https://www.shiyanlou.com/user/235723">主页</a></li>
                        <li><a href="https://www.shiyanlou.com/user/friends">好友</a></li>
                        <li><a href="https://www.shiyanlou.com/user/message">
                            <span class="position-relative"><span class="header-msg-mark" style="display:none;"></span>消息</span>
                        </a></li>
                        <li><a href="https://www.shiyanlou.com/user/profile">设置</a></li>
                        <li rolw="separator" class="divider"></li>
                        <li><a href="https://www.shiyanlou.com/logout">退出</a></li>
                    </ul>
                </li>
            </ul>
            

            <form class="navbar-form navbar-right" action="https://www.shiyanlou.com/search" method="get" role="search">
                <div class="form-group">
                    <input type="text" class="form-control" name="search" autocomplete="off" placeholder="搜索 课程/问答">
                </div>
            </form>
        </div>
    </div>
</nav>




        
	



	
	

	


<div class="container layout layout-margin-top">
    
<ol class="breadcrumb">
    <li><a href="https://www.shiyanlou.com/courses/">全部课程</a></li>
    <li>
        <a href="https://www.shiyanlou.com/courses/707">神经网络实现人脸识别任务</a>
    </li>
    <li class="active">
        无监督学习进行人脸数据降维
    </li>
</ol>

    <div class="row">
        <div class="col-md-9 layout-body">
            
<div class="mobile-alert alert alert-danger">在线实验，请到PC端体验</div>
<div id="preview" class="markdown-body"><h1 id="-">自编码器进行人脸数据降维</h1>
<h2 id="-">一、课程介绍</h2>
<h3 id="1-1-">1.1 内容简介</h3>
<p>虽然目前深度学习取得了非常不错的成果，但是由于网络结构复杂，训练非常耗时。而且目前要进行深度学习的分类训练需要大量的带标记数据，对这些数据进行标记是非常耗时耗人力的。因此我们可用<code>无监督学习</code>利用无标记数据提取特征，并且利用无标记数据基于无监督学习对数据进行降维后，结合有标记数据基于<code>有监督学习</code>进行分类训练，实现人脸识别，图像分类等任务。</p>
<p>本次课程我们将利用在 <a href="https://www.shiyanlou.com/courses/696" target="_blank">基于无监督学习的自编码器实现</a> 课程中介绍过的自编码器，实现对<a href="http://vision.ucsd.edu/content/extended-yale-face-database-b-b" target="_blank">耶鲁大学人脸数据库B+</a>中的人脸图片数据进行降维，再利用降维后的人脸数据进行<code>有监督神经网络学习</code>进行分类器训练，最终达到人脸识别的目的。</p>
<h3 id="1-2-">1.2 知识点</h3>
<ul>
<li>人脸识别</li>
<li>人脸数据库</li>
<li>数据降维</li>
</ul>
<h3 id="1-3-">1.3 课程流程</h3>
<p>本次人脸识别应用的实现流程为：</p>
<ol>
<li>人脸数据准备</li>
<li>人脸识别自编码器实现</li>
<li>人脸识别分类器实现</li>
</ol>
<blockquote>
<ul>
<li>本次课程需同学们具备有<code>机器学习</code>算法里<code>神经网络</code>的基础, 及对<code>python</code>依赖包<code>numpy</code>和<code>matplotlib</code>有一定了解</li>
</ul>
</blockquote>
<h3 id="1-4-">1.4 人脸自编码器效果截图</h3>
<p>本次课程实现的是对<code>Yale B+数据库</code>中的4张人脸进行识别的任务，以下每一列分别代表其中的一个人</p>
<p>原始图像：</p>
<p><img src="./无监督学习进行人脸数据降维 - 实验楼_files/wm" alt="original faces"></p>
<p>第100次自编码器训练结果：</p>
<p><img src="./无监督学习进行人脸数据降维 - 实验楼_files/wm(1)" alt="iter 100"></p>
<p>第200次自编码器训练结果：</p>
<p><img src="./无监督学习进行人脸数据降维 - 实验楼_files/wm(2)" alt="iter 200"></p>
<p>第300次自编码器训练结果：</p>
<p><img src="./无监督学习进行人脸数据降维 - 实验楼_files/wm(3)" alt="iter 300"></p>
<h2 id="-">二、实验原理</h2>
<h3 id="2-1-yale-b-">2.1 人脸识别任务及 yale B+ 数据库介绍</h3>
<p>人脸识别维基百科定义：</p>
<blockquote>
<p>广义的人脸识别实际包括构建人脸识别系统的一系列相关技术，包括人脸图像采集、人脸定位、人脸识别预处理、身份确认以及身份查找等；而狭义的人脸识别特指通过人脸进行身份确认或者身份查找的技术或系统。
人脸识别是一项热门的计算机技术研究领域，它属于生物特征识别技术，是对生物体（一般特指人）本身的生物特征来区分生物体个体。生物特征识别技术所研究的生物特征包括脸、指纹、手掌纹、虹膜、视网膜、声音（语音）、体形、个人习惯（例如敲击键盘的力度和频率、签字）等，相应的识别技术就有人脸识别、指纹识别、掌纹识别、虹膜识别、视网膜识别、语音识别（用语音识别可以进行身份识别，也可以进行语音内容的识别，只有前者属于生物特征识别技术）、体形识别、键盘敲击识别、签字识别等。</p>
</blockquote>
<p>本次实验，我们所用的<a href="http://vision.ucsd.edu/content/extended-yale-face-database-b-b" target="_blank">耶鲁大学人脸数据库B+</a></p>
<p><img src="./无监督学习进行人脸数据降维 - 实验楼_files/wm(4)" alt="B+数据库"></p>
<p>可点击<code>Download</code>下方的链接进入下载页面：</p>
<p><img src="./无监督学习进行人脸数据降维 - 实验楼_files/wm(5)" alt="download_pad"></p>
<p>点击<code>Cropped_Images</code>下载裁剪过后的数据，裁剪好的图片数据中不包含其他背景，仅有人脸（不包括头发，耳朵等），本次课程中只用了下载好的数据<code>CroppedYale</code>中的其中四个人脸数据集<code>yaleB01</code>,<code>yaleB02</code>,<code>yaleB03</code>和<code>yaleB04</code>。数据库中每张人脸数据大小为<code>192 x 168</code>，对于每个人都有64张人脸图片，分别是在不同光照条件下拍摄得的。 为了节约计算时间，我们将原始数据的维度改成<code>48 x 42</code>，并且从每个文件夹中选出20张图片当做无监督学习时的数据集，14张作为有监督训练时的训练数据，10张为有监督训练的测试数据。</p>
<h3 id="2-2-">2.2 神经网络总结构</h3>
<p>我们的神经网络由两部分组成，第一部分为<code>自编码器</code>训练完毕后的编码部分，第二部分为<code>有监督训练</code>单层网络，在<a href="https://www.shiyanlou.com/courses/696" target="_blank">基于无监督学习的自编码器实现</a>中我们已经详细地介绍过自编码器的原理，这里我们将运用其作为对人脸进行<code>数据降维</code>,再结合有监督学习结合有标记数据进行分类训练。</p>
<p>自编码器结构：</p>
<p><img src="./无监督学习进行人脸数据降维 - 实验楼_files/wm(6)" alt="自编码器"></p>
<p>自编码器网络结构：</p>
<p><img src="./无监督学习进行人脸数据降维 - 实验楼_files/wm(7)" alt="自编码器_网络结构"></p>
<p>总体网络结构，对于每个不同的人，我们采用一个四维列向量对其表达，这些列向量即是对不同人（类别）的<code>数据标记</code>：</p>
<p><img src="./无监督学习进行人脸数据降维 - 实验楼_files/wm(8)" alt="神经网络总体结构"></p>
<h2 id="-">三、实验操作</h2>
<h3 id="3-1-python-">3.1 下载安装第三方python包</h3>
<p>安装实验所需的第三方包 scipy, numpy, matplotlib，及下载所需的实验数据，及下载安装python-tk</p>
<pre><code class="lang-bash hljs">sudo pip install scipy
sudo pip install numpy
sudo pip install matplotlib
sudo apt-get install python-tk
</code></pre>
<h3 id="3-2-">3.2 实验数据下载</h3>
<p>由于处理数据是一个繁琐的过程，并不是本次课程主要核心内容，因此我们已将数据处理好并放置在<code>yaleB_face_dataset.mat</code>文件中，可通过以下命运获取此文件：</p>
<pre><code class="lang-python hljs">wget http://labfile.oss.aliyuncs.com/courses/<span class="hljs-number">707</span>/yaleB_face_dataset.mat
</code></pre>
<h3 id="3-3-">3.3 自编码器实现</h3>
<p>在与<code>yaleB_face_database.mat</code>同个目录下创建<code>face_recognition.py</code>并编写，导入相关python包</p>
<pre><code class="lang-bash hljs">vim face_recognition.py
</code></pre>
<pre><code class="lang-python hljs"><span class="hljs-keyword">import</span> scipy.io <span class="hljs-keyword">as</span> scio
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> random
</code></pre>
<blockquote>
<p>使用<code>matplotlib</code>绘图时，在代码的最后需加上<code>plt.show()</code>展示效果。</p>
</blockquote>
<p>进行神经网络所必须的<code>前向传播计算 feedforward computing</code> 和 <code>误差反向传播 backpropagation</code> 实现。</p>
<p>前向传播计算：</p>
<pre><code class="lang-python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">feedforward</span><span class="hljs-params">(w,a,x)</span>:</span>
    <span class="hljs-comment"># sigmoid 激活函数</span>
    f = <span class="hljs-keyword">lambda</span> s: <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + np.exp(-s)) 

    w = np.array(w)
    temp = np.array(np.concatenate((a,x),axis=<span class="hljs-number">0</span>))
    z_next = np.dot(w , temp)

    <span class="hljs-keyword">return</span> f(z_next), z_next
</code></pre>
<p>误差反向传播计算：</p>
<pre><code class="lang-python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">backprop</span><span class="hljs-params">(w,z,delta_next)</span>:</span>

    <span class="hljs-comment"># sigmoid 激活函数</span>
    f = <span class="hljs-keyword">lambda</span> s: np.array(<span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + np.exp(-s)))


    <span class="hljs-comment"># sigmoid 激活函数的导数</span>
    df = <span class="hljs-keyword">lambda</span> s: f(s) * (<span class="hljs-number">1</span> - f(s))


    delta = df(z) * np.dot(w.T,delta_next)    

    <span class="hljs-keyword">return</span> delta
</code></pre>
<p>导入准备好的人脸数据，并对其进行归一化：</p>
<pre><code class="lang-python hljs">DataSet = scio.loadmat(<span class="hljs-string">'yaleB_face_dataset.mat'</span>)
unlabeledData = DataSet[<span class="hljs-string">'unlabeled_data'</span>]

dataset_size = <span class="hljs-number">80</span> <span class="hljs-comment"># 我们所准备无标签的人脸图片数据数量</span>
unlabeled_data = np.zeros(unlabeledData.shape)

<span class="hljs-comment"># 利用z-score归一化方法归一数据</span>
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(dataset_size):
    tmp = unlabeledData[:,i] / <span class="hljs-number">255.</span>
    unlabeled_data[:,i] = (tmp - np.mean(tmp)) / np.std(tmp)
</code></pre>
<p>设置自编码器无监督训练参数，及神经网络结构：</p>
<pre><code class="lang-python hljs">alpha = <span class="hljs-number">0.5</span> <span class="hljs-comment"># 学习步长</span>
max_epoch = <span class="hljs-number">300</span> <span class="hljs-comment"># 自编码器训练总次数</span>
mini_batch = <span class="hljs-number">10</span> <span class="hljs-comment"># 最小批训练时，每次使用10个样本同时进行训练</span>
height = <span class="hljs-number">48</span>  <span class="hljs-comment"># 人脸数据图片的高度</span>
width = <span class="hljs-number">42</span> <span class="hljs-comment"># 人脸数据图片的宽度</span>
imgSize = height * width 

<span class="hljs-comment"># 神经网络结构</span>
hidden_node = <span class="hljs-number">60</span> <span class="hljs-comment"># 网络隐藏层节点数目</span>
hidden_layer = <span class="hljs-number">2</span> 
layer_struc = [[imgSize, <span class="hljs-number">1</span>],
               [<span class="hljs-number">0</span>, hidden_node],
               [<span class="hljs-number">0</span>, imgSize]]
layer_num = <span class="hljs-number">3</span> <span class="hljs-comment"># 网络层次数目</span>

<span class="hljs-comment"># 初始化无监督网络的权值</span>
w = []
<span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> range(layer_num<span class="hljs-number">-1</span>):
    w.append(np.random.randn(layer_struc[l+<span class="hljs-number">1</span>][<span class="hljs-number">1</span>],sum(layer_struc[l])))

<span class="hljs-comment"># 定义神经网络的外部节点数目</span>
X = []
X.append(np.array(unlabeled_data[:,:]))
X.append(np.zeros((<span class="hljs-number">0</span>,dataset_size)))
X.append(np.zeros((<span class="hljs-number">0</span>,dataset_size)))

<span class="hljs-comment"># 初始化在网络训练过程中，进行误差反向传播所需的 δ</span>
delta = []
<span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> range(layer_num):
    delta.append([])
</code></pre>
<p>从预先准备好的人脸数据中显示其中每个人的一张图片,原始图片将和训练过程中自编码器的输出结果展示在同一面板中</p>
<pre><code class="lang-python hljs"><span class="hljs-comment"># 定义结果展示参数</span>
nRow = max_epoch / <span class="hljs-number">100</span> + <span class="hljs-number">1</span> 
nColumn = <span class="hljs-number">4</span>   
eachFaceNum = <span class="hljs-number">20</span> <span class="hljs-comment"># 对于每个人都有20张未标记图像数据</span>

<span class="hljs-comment"># 在第一行中展示原始图像</span>
<span class="hljs-keyword">for</span> iImg <span class="hljs-keyword">in</span> range(nColumn):
    ax = plt.subplot(nRow, nColumn, iImg+<span class="hljs-number">1</span>)
    plt.imshow(unlabeledData[:,eachFaceNum * iImg + <span class="hljs-number">1</span>].reshape((width,height)).T, cmap= plt.cm.gray)
    ax.get_xaxis().set_visible(<span class="hljs-keyword">False</span>)
    ax.get_yaxis().set_visible(<span class="hljs-keyword">False</span>)
</code></pre>
<p>万事俱备，现在我们开始人脸图像自编码器的训练过程：</p>
<pre><code class="lang-python hljs"><span class="hljs-comment">#无监督训练</span>
count = <span class="hljs-number">0</span> <span class="hljs-comment"># 记录训练次数</span>
print(<span class="hljs-string">'Autoencoder training start..'</span>)
<span class="hljs-keyword">for</span> iter <span class="hljs-keyword">in</span> range(max_epoch):

    <span class="hljs-comment"># 定义随机洗牌下标</span>
    ind = list(range(dataset_size))
    random.shuffle(ind)

    a = []
    z = []
    z.append([])
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(int(np.ceil(dataset_size / mini_batch))):
        a.append(np.zeros((layer_struc[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>], mini_batch)))
        x = []
        <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> range(layer_num):
            x.append( X[l][:,ind[i*mini_batch : min((i+<span class="hljs-number">1</span>)*mini_batch, dataset_size)]])

        y = unlabeled_data[:,ind[i*mini_batch:min((i+<span class="hljs-number">1</span>)*mini_batch,dataset_size)]]
        <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> range(layer_num<span class="hljs-number">-1</span>):
            a.append([])
            z.append([])
            a[l+<span class="hljs-number">1</span>],z[l+<span class="hljs-number">1</span>] = feedforward(w[l],a[l],x[l])


        delta[layer_num<span class="hljs-number">-1</span>] = np.array(a[layer_num<span class="hljs-number">-1</span>] - y) * np.array(a[layer_num<span class="hljs-number">-1</span>])
        delta[layer_num<span class="hljs-number">-1</span>] = delta[layer_num<span class="hljs-number">-1</span>] * np.array(<span class="hljs-number">1</span>-a[layer_num<span class="hljs-number">-1</span>])

        <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> range(layer_num<span class="hljs-number">-2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">-1</span>):
            delta[l] = backprop(w[l],z[l],delta[l+<span class="hljs-number">1</span>])

        <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> range(layer_num<span class="hljs-number">-1</span>):
            dw = np.dot(delta[l+<span class="hljs-number">1</span>], np.concatenate((a[l],x[l]),axis=<span class="hljs-number">0</span>).T) / mini_batch
            w[l] = w[l] - alpha * dw

    count = count + <span class="hljs-number">1</span>  



    <span class="hljs-comment"># 每训练100次展示一次自编码器目前对原始图像的输出结果</span>
    <span class="hljs-keyword">if</span> np.mod(iter+<span class="hljs-number">1</span>,<span class="hljs-number">100</span>) == <span class="hljs-number">0</span> :
        b = []
        b.append(np.zeros((layer_struc[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>],dataset_size)))

        <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> range(layer_num<span class="hljs-number">-1</span>):
            tempA, tempZ = feedforward(w[l], b[l], X[l])                
            b.append(tempA)

        <span class="hljs-keyword">for</span> iImg <span class="hljs-keyword">in</span> range(nColumn):
            ax = plt.subplot(nRow,nColumn, iImg + nColumn * (iter+<span class="hljs-number">1</span>)/<span class="hljs-number">100</span> + <span class="hljs-number">1</span>)
            tmp = b[layer_num<span class="hljs-number">-1</span>][:,eachFaceNum * iImg + <span class="hljs-number">1</span>]
            dis_result = ((tmp * np.std(tmp)) + np.mean(tmp)).reshape(width,height).T
            plt.imshow(dis_result,cmap= plt.cm.gray) 
            ax.get_xaxis().set_visible(<span class="hljs-keyword">False</span>)
            ax.get_yaxis().set_visible(<span class="hljs-keyword">False</span>)

        print(<span class="hljs-string">'Learning epoch:'</span>, count, <span class="hljs-string">'/'</span>, max_epoch)
</code></pre>
<h2 id="-">四、 总结</h2>
<p>这节课程我们介绍了一个人脸数据库，并且利用自编码器对其进行了数据降维，将维度从<code>2016</code>降至<code>56</code>，下节课程我们将实现利用将这个降维后的数据进行有监督训练的网络，最终实现人脸识别的任务。</p>
<p>我们也可通过以下代码，展示自编码器训练结束时，自编码器对数据的编码效果：</p>
<pre><code class="lang-python hljs">fig2 = plt.figure(<span class="hljs-number">2</span>)

<span class="hljs-comment"># 获得编码结果</span>
code_result, tempZ = feedforward(w[<span class="hljs-number">0</span>], b[<span class="hljs-number">0</span>], X[<span class="hljs-number">0</span>])

<span class="hljs-comment"># 展示原始数据图</span>
<span class="hljs-keyword">for</span> iImg <span class="hljs-keyword">in</span> range(nColumn):
    ax = plt.subplot(<span class="hljs-number">2</span>, nColumn, iImg+<span class="hljs-number">1</span>)
    plt.imshow(unlabeled_data[:,eachFaceNum * iImg + <span class="hljs-number">1</span>].reshape((width,height)).T, cmap= plt.cm.gray)
    ax.get_xaxis().set_visible(<span class="hljs-keyword">False</span>)
    ax.get_yaxis().set_visible(<span class="hljs-keyword">False</span>)

<span class="hljs-comment"># 展示对应的编码结果</span>
<span class="hljs-keyword">for</span> iImg <span class="hljs-keyword">in</span> range(nColumn):
    ax = plt.subplot(<span class="hljs-number">2</span>,nColumn,iImg+nColumn+<span class="hljs-number">1</span>)
    plt.imshow(code_result[:,eachDigitNum * iImg + <span class="hljs-number">1</span>].reshape((hidden_node,<span class="hljs-number">1</span>)), cmap=plt.cm.gray)
    ax.get_xaxis().set_visible(<span class="hljs-keyword">False</span>)
    ax.get_yaxis().set_visible(<span class="hljs-keyword">False</span>)
</code></pre>
<p>编码效果图：</p>
<p><img src="./无监督学习进行人脸数据降维 - 实验楼_files/wm(9)" alt="编码结果"></p>
<h2 id="-">五、参考阅读</h2>
<ul>
<li><a href="https://www.kairos.com/blog/60-facial-recognition-databases" target="_blank">60个人脸数据库介绍</a></li>
<li><a href="http://ufldl.stanford.edu/wiki/index.php/Stacked_Autoencoders" target="_blank">UFLDL-栈式自编码器</a></li>
<li><a href="https://www.zhihu.com/question/41490383" target="_blank">知乎-为什么稀疏自编码器很少见到多层的</a></li>
</ul>
</div>

<textarea id="editor" style="display:none;"># 自编码器进行人脸数据降维

## 一、课程介绍

### 1.1 内容简介

虽然目前深度学习取得了非常不错的成果，但是由于网络结构复杂，训练非常耗时。而且目前要进行深度学习的分类训练需要大量的带标记数据，对这些数据进行标记是非常耗时耗人力的。因此我们可用`无监督学习`利用无标记数据提取特征，并且利用无标记数据基于无监督学习对数据进行降维后，结合有标记数据基于`有监督学习`进行分类训练，实现人脸识别，图像分类等任务。

本次课程我们将利用在 [基于无监督学习的自编码器实现](https://www.shiyanlou.com/courses/696) 课程中介绍过的自编码器，实现对[耶鲁大学人脸数据库B+](http://vision.ucsd.edu/content/extended-yale-face-database-b-b)中的人脸图片数据进行降维，再利用降维后的人脸数据进行`有监督神经网络学习`进行分类器训练，最终达到人脸识别的目的。

### 1.2 知识点

- 人脸识别
- 人脸数据库
- 数据降维

### 1.3 课程流程

本次人脸识别应用的实现流程为：

1. 人脸数据准备
2. 人脸识别自编码器实现
3. 人脸识别分类器实现

&gt; - 本次课程需同学们具备有`机器学习`算法里`神经网络`的基础, 及对`python`依赖包`numpy`和`matplotlib`有一定了解

### 1.4 人脸自编码器效果截图

本次课程实现的是对`Yale B+数据库`中的4张人脸进行识别的任务，以下每一列分别代表其中的一个人

原始图像：

![original faces](https://dn-anything-about-doc.qbox.me/document-uid291340labid2300timestamp1479451308403.png/wm)

第100次自编码器训练结果：

![iter 100](https://dn-anything-about-doc.qbox.me/document-uid291340labid2300timestamp1479451337873.png/wm)

第200次自编码器训练结果：

![iter 200](https://dn-anything-about-doc.qbox.me/document-uid291340labid2300timestamp1479451383444.png/wm)

第300次自编码器训练结果：

![iter 300](https://dn-anything-about-doc.qbox.me/document-uid291340labid2300timestamp1479451409401.png/wm)

## 二、实验原理

### 2.1 人脸识别任务及 yale B+ 数据库介绍

人脸识别维基百科定义：

&gt; 广义的人脸识别实际包括构建人脸识别系统的一系列相关技术，包括人脸图像采集、人脸定位、人脸识别预处理、身份确认以及身份查找等；而狭义的人脸识别特指通过人脸进行身份确认或者身份查找的技术或系统。
人脸识别是一项热门的计算机技术研究领域，它属于生物特征识别技术，是对生物体（一般特指人）本身的生物特征来区分生物体个体。生物特征识别技术所研究的生物特征包括脸、指纹、手掌纹、虹膜、视网膜、声音（语音）、体形、个人习惯（例如敲击键盘的力度和频率、签字）等，相应的识别技术就有人脸识别、指纹识别、掌纹识别、虹膜识别、视网膜识别、语音识别（用语音识别可以进行身份识别，也可以进行语音内容的识别，只有前者属于生物特征识别技术）、体形识别、键盘敲击识别、签字识别等。


本次实验，我们所用的[耶鲁大学人脸数据库B+](http://vision.ucsd.edu/content/extended-yale-face-database-b-b)

![B+数据库](https://dn-anything-about-doc.qbox.me/document-uid291340labid2300timestamp1479455279939.png/wm)

可点击`Download`下方的链接进入下载页面：

![download_pad](https://dn-anything-about-doc.qbox.me/document-uid291340labid2300timestamp1479455996199.png/wm)

点击`Cropped_Images`下载裁剪过后的数据，裁剪好的图片数据中不包含其他背景，仅有人脸（不包括头发，耳朵等），本次课程中只用了下载好的数据`CroppedYale`中的其中四个人脸数据集`yaleB01`,`yaleB02`,`yaleB03`和`yaleB04`。数据库中每张人脸数据大小为`192 x 168`，对于每个人都有64张人脸图片，分别是在不同光照条件下拍摄得的。 为了节约计算时间，我们将原始数据的维度改成`48 x 42`，并且从每个文件夹中选出20张图片当做无监督学习时的数据集，14张作为有监督训练时的训练数据，10张为有监督训练的测试数据。

### 2.2 神经网络总结构

我们的神经网络由两部分组成，第一部分为`自编码器`训练完毕后的编码部分，第二部分为`有监督训练`单层网络，在[基于无监督学习的自编码器实现](https://www.shiyanlou.com/courses/696)中我们已经详细地介绍过自编码器的原理，这里我们将运用其作为对人脸进行`数据降维`,再结合有监督学习结合有标记数据进行分类训练。

自编码器结构：

![自编码器](https://dn-anything-about-doc.qbox.me/document-uid291340labid2300timestamp1479458755797.png/wm)

自编码器网络结构：

![自编码器_网络结构](https://dn-anything-about-doc.qbox.me/document-uid291340labid2300timestamp1479458805483.png/wm)

总体网络结构，对于每个不同的人，我们采用一个四维列向量对其表达，这些列向量即是对不同人（类别）的`数据标记`：

![神经网络总体结构](https://dn-anything-about-doc.qbox.me/document-uid291340labid2300timestamp1479458896226.png/wm)

## 三、实验操作

### 3.1 下载安装第三方python包

安装实验所需的第三方包 scipy, numpy, matplotlib，及下载所需的实验数据，及下载安装python-tk
```bash
sudo pip install scipy
sudo pip install numpy
sudo pip install matplotlib
sudo apt-get install python-tk
```

### 3.2 实验数据下载

由于处理数据是一个繁琐的过程，并不是本次课程主要核心内容，因此我们已将数据处理好并放置在`yaleB_face_dataset.mat`文件中，可通过以下命运获取此文件：

```python
wget http://labfile.oss.aliyuncs.com/courses/707/yaleB_face_dataset.mat
```


### 3.3 自编码器实现

在与`yaleB_face_database.mat`同个目录下创建`face_recognition.py`并编写，导入相关python包
```bash
vim face_recognition.py
```

```python
import scipy.io as scio
import numpy as np
import matplotlib.pyplot as plt
import random
```

&gt; 使用`matplotlib`绘图时，在代码的最后需加上`plt.show()`展示效果。

进行神经网络所必须的`前向传播计算 feedforward computing` 和 `误差反向传播 backpropagation` 实现。

前向传播计算：

``` python
def feedforward(w,a,x):
    # sigmoid 激活函数
    f = lambda s: 1 / (1 + np.exp(-s)) 
    
    w = np.array(w)
    temp = np.array(np.concatenate((a,x),axis=0))
    z_next = np.dot(w , temp)
    
    return f(z_next), z_next

```

误差反向传播计算：

```python
def backprop(w,z,delta_next):

    # sigmoid 激活函数
    f = lambda s: np.array(1 / (1 + np.exp(-s)))
    

    # sigmoid 激活函数的导数
    df = lambda s: f(s) * (1 - f(s))
    
    
    delta = df(z) * np.dot(w.T,delta_next)    

    return delta
```

导入准备好的人脸数据，并对其进行归一化：
``` python
DataSet = scio.loadmat('yaleB_face_dataset.mat')
unlabeledData = DataSet['unlabeled_data']

dataset_size = 80 # 我们所准备无标签的人脸图片数据数量
unlabeled_data = np.zeros(unlabeledData.shape)

# 利用z-score归一化方法归一数据
for i in range(dataset_size):
    tmp = unlabeledData[:,i] / 255.
    unlabeled_data[:,i] = (tmp - np.mean(tmp)) / np.std(tmp)    
```

设置自编码器无监督训练参数，及神经网络结构：

```python
alpha = 0.5 # 学习步长
max_epoch = 300 # 自编码器训练总次数
mini_batch = 10 # 最小批训练时，每次使用10个样本同时进行训练
height = 48  # 人脸数据图片的高度
width = 42 # 人脸数据图片的宽度
imgSize = height * width 
   
# 神经网络结构
hidden_node = 60 # 网络隐藏层节点数目
hidden_layer = 2 
layer_struc = [[imgSize, 1],
               [0, hidden_node],
               [0, imgSize]]
layer_num = 3 # 网络层次数目

# 初始化无监督网络的权值
w = []
for l in range(layer_num-1):
    w.append(np.random.randn(layer_struc[l+1][1],sum(layer_struc[l])))

# 定义神经网络的外部节点数目
X = []
X.append(np.array(unlabeled_data[:,:]))
X.append(np.zeros((0,dataset_size)))
X.append(np.zeros((0,dataset_size)))

# 初始化在网络训练过程中，进行误差反向传播所需的 δ
delta = []
for l in range(layer_num):
    delta.append([])
```

从预先准备好的人脸数据中显示其中每个人的一张图片,原始图片将和训练过程中自编码器的输出结果展示在同一面板中

```python
# 定义结果展示参数
nRow = max_epoch / 100 + 1 
nColumn = 4   
eachFaceNum = 20 # 对于每个人都有20张未标记图像数据

# 在第一行中展示原始图像
for iImg in range(nColumn):
    ax = plt.subplot(nRow, nColumn, iImg+1)
    plt.imshow(unlabeledData[:,eachFaceNum * iImg + 1].reshape((width,height)).T, cmap= plt.cm.gray)
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
```

万事俱备，现在我们开始人脸图像自编码器的训练过程：
```python
#无监督训练
count = 0 # 记录训练次数
print('Autoencoder training start..')
for iter in range(max_epoch):

    # 定义随机洗牌下标
    ind = list(range(dataset_size))
    random.shuffle(ind)
    
    a = []
    z = []
    z.append([])
    for i in range(int(np.ceil(dataset_size / mini_batch))):
        a.append(np.zeros((layer_struc[0][1], mini_batch)))
        x = []
        for l in range(layer_num):
            x.append( X[l][:,ind[i*mini_batch : min((i+1)*mini_batch, dataset_size)]])

        y = unlabeled_data[:,ind[i*mini_batch:min((i+1)*mini_batch,dataset_size)]]
        for l in range(layer_num-1):
            a.append([])
            z.append([])
            a[l+1],z[l+1] = feedforward(w[l],a[l],x[l])
        
        
        delta[layer_num-1] = np.array(a[layer_num-1] - y) * np.array(a[layer_num-1])
        delta[layer_num-1] = delta[layer_num-1] * np.array(1-a[layer_num-1])
        
        for l in range(layer_num-2, 0, -1):
            delta[l] = backprop(w[l],z[l],delta[l+1])

        for l in range(layer_num-1):
            dw = np.dot(delta[l+1], np.concatenate((a[l],x[l]),axis=0).T) / mini_batch
            w[l] = w[l] - alpha * dw
   
    count = count + 1  
     
    
   
    # 每训练100次展示一次自编码器目前对原始图像的输出结果
    if np.mod(iter+1,100) == 0 :
        b = []
        b.append(np.zeros((layer_struc[0][1],dataset_size)))

        for l in range(layer_num-1):
            tempA, tempZ = feedforward(w[l], b[l], X[l])                
            b.append(tempA)

        for iImg in range(nColumn):
            ax = plt.subplot(nRow,nColumn, iImg + nColumn * (iter+1)/100 + 1)
            tmp = b[layer_num-1][:,eachFaceNum * iImg + 1]
            dis_result = ((tmp * np.std(tmp)) + np.mean(tmp)).reshape(width,height).T
            plt.imshow(dis_result,cmap= plt.cm.gray) 
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
                        
        print('Learning epoch:', count, '/', max_epoch)
```

## 四、 总结

这节课程我们介绍了一个人脸数据库，并且利用自编码器对其进行了数据降维，将维度从`2016`降至`56`，下节课程我们将实现利用将这个降维后的数据进行有监督训练的网络，最终实现人脸识别的任务。

我们也可通过以下代码，展示自编码器训练结束时，自编码器对数据的编码效果：

```python
fig2 = plt.figure(2)

# 获得编码结果
code_result, tempZ = feedforward(w[0], b[0], X[0])

# 展示原始数据图
for iImg in range(nColumn):
    ax = plt.subplot(2, nColumn, iImg+1)
    plt.imshow(unlabeled_data[:,eachFaceNum * iImg + 1].reshape((width,height)).T, cmap= plt.cm.gray)
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

# 展示对应的编码结果
for iImg in range(nColumn):
    ax = plt.subplot(2,nColumn,iImg+nColumn+1)
    plt.imshow(code_result[:,eachDigitNum * iImg + 1].reshape((hidden_node,1)), cmap=plt.cm.gray)
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
```

编码效果图：

![编码结果](https://dn-anything-about-doc.qbox.me/document-uid291340labid2300timestamp1479462081866.png/wm)

## 五、参考阅读

- [60个人脸数据库介绍](https://www.kairos.com/blog/60-facial-recognition-databases)
- [UFLDL-栈式自编码器](http://ufldl.stanford.edu/wiki/index.php/Stacked_Autoencoders)
- [知乎-为什么稀疏自编码器很少见到多层的](https://www.zhihu.com/question/41490383)
</textarea>
<nav>
    <ul class="pager">
        
        
        <li class="next">
            <a href="https://www.shiyanlou.com/courses/707/labs/2301/document">
                下一节 <i class="fa fa-chevron-right"></i>
            </a>
        </li>
        
    </ul>
</nav>


    
    <div class="vip-banner">
        
        动手实践是学习 IT 技术最有效的方式！
        
        

        

        
            
        

        
        <a class="btn   lab-item-start" data-mobile-url="/courses/document/2300" data-url="/courses/start/2300" data-next="/courses/running">开始实验</a>
    </div>
    


        </div>
        <div class="col-md-3 layout-side">
            
    <div class="side-image side-image-pc">
        <img src="./无监督学习进行人脸数据降维 - 实验楼_files/1479805621420.png">
    </div>
    
    

    
        
    


    
        
<div class="sidebox mooc-teacher">
    <div class="sidebox-header mooc-header">
        <h4 class="sidebox-title">课程教师</h4>
    </div>
    <div class="sidebox-body mooc-content">
        <a href="https://www.shiyanlou.com/user/291340" target="_blank">
            <img src="./无监督学习进行人脸数据降维 - 实验楼_files/gravatar291340.png">
        </a>
        <div class="mooc-info">
            <div class="name"><strong>zyj061</strong> </div>
            
            <div class="courses">共发布过<strong>3</strong>门课程</div>
        </div>
        <div class="mooc-extra-info">
            <div class="word long-paragraph">
                
            </div>
        </div>
    </div>
    <div class="sidebox-footer mooc-footer">
        <a href="https://www.shiyanlou.com/teacher/291340" target="_blank">查看老师的所有课程 &gt;</a>
    </div>
</div>

    
    
    
    
    <div class="side-image">
    <a href="https://www.shiyanlou.com/vip" target="_blank">
        <img src="./无监督学习进行人脸数据降维 - 实验楼_files/banner-vip.png">
    </a>
</div>
    
    
    
    
    

        </div>
    </div>
</div>


	<div class="modal fade" id="invite-user" tabindex="-1" role="dialog" aria-hidden="true">
		<div class="modal-dialog">
			<div class="modal-content">
				<div class="modal-header">
					<button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">×</span><span class="sr-only">Close</span></button>
                    <h4 class="modal-title">邀请好友，双方都可获赠实验豆！</h4>
				</div>
				<div class="modal-body">
                    
					<div class="form-label">
                        分享专属链接给好友，或粘贴到QQ群/微博/论坛，好友注册后，您和好友将分别获赠3个实验豆！
                    </div>
					<input type="text" id="bstext" class="form-invite" value="https://www.shiyanlou.com/register?inviter=NTY0MzE5MjQ4Mzk4">              
                    
					<div id="msg-modal"></div>
				</div>
			</div>
		</div>
	</div>


	
    
        
        
<div class="footer">
    <div class="container">
        <div class="row">
            <div class="col-md-4 clearfix footer-col">
                <img src="./无监督学习进行人脸数据降维 - 实验楼_files/logo_03.png">
                <div class="footer-slogan">动手做实验，轻松学编程</div>
                <div class="col-xs-2">
                    <div class="social-item footer-weixin-item">
                        <i class="fa fa-weixin"></i>
                        <div class="footer-weixin">
                            <img src="./无监督学习进行人脸数据降维 - 实验楼_files/footer-weixin.png">
                        </div>
                    </div>
                </div>
                <div class="col-xs-2">
                    <div class="social-item footer-qq-item" data-original-title="" title="">
                        <i class="fa fa-qq"></i>
                    </div>
                </div>
                <div class="col-xs-2">
                    <div class="social-item footer-weibo-item">
                        <a href="http://weibo.com/shiyanlou2013" target="_blank">
                            <i class="fa fa-weibo"></i>
                        </a>
                    </div>
                </div>
            </div>
            <div class="col-xs-6 col-sm-3 col-md-2 footer-col">
                <div class="col-title">公司</div>
                <a href="https://www.shiyanlou.com/aboutus" target="_blank">关于我们</a><br>
                <a href="https://www.shiyanlou.com/contact" target="_blank">联系我们</a><br>
                <a href="http://www.simplecloud.cn/jobs.html" target="_blank">加入我们</a><br>
                <a href="https://blog.shiyanlou.com/" target="_blank">技术博客</a><br>
            </div>
            <div class="col-xs-6 col-sm-3 col-md-2 footer-col">
                <div class="col-title">合作</div>
                <a href="https://www.shiyanlou.com/contribute" target="_blank">我要投稿</a><br>
                <a href="https://www.shiyanlou.com/labs" target="_blank">教师合作</a><br>
                <a href="https://www.shiyanlou.com/edu/" target="_blank">高校合作</a><br>
                <a href="https://www.shiyanlou.com/friends" target="_blank">友情链接</a>
            </div>
            <div class="col-xs-6 col-sm-3 col-md-2 footer-col">
                <div class="col-title">服务</div>
                <a href="https://www.shiyanlou.com/bootcamp/" target="_blank">实战训练营</a><br>
                <a href="https://www.shiyanlou.com/vip" target="_blank">会员服务</a><br>
                <a href="https://www.shiyanlou.com/courses/reports" target="_blank">实验报告</a><br>
                <a href="https://www.shiyanlou.com/questions/?tag=%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98" target="_blank">常见问题</a><br>
                <a href="https://www.shiyanlou.com/privacy" target="_blank">隐私条款</a>
            </div>
            <div class="col-xs-6 col-sm-3 col-md-2 footer-col">
                <div class="col-title">学习路径</div>
                <a href="https://www.shiyanlou.com/paths/python" target="_blank">Python学习路径</a><br>
                <a href="https://www.shiyanlou.com/paths/linuxdev" target="_blank">Linux学习路径</a><br>
                <a href="https://www.shiyanlou.com/paths/bigdata" target="_blank">大数据学习路径</a><br>
                <a href="https://www.shiyanlou.com/paths/java" target="_blank">Java学习路径</a><br>
                <a href="https://www.shiyanlou.com/paths/php" target="_blank">PHP学习路径</a><br>
                <a href="https://www.shiyanlou.com/paths/" ,="" target="_blank">全部</a>
            </div>
        </div>
    </div>
    <div class="text-center copyright">
        <span>Copyright @2013-2016 实验楼在线教育</span>
        <span class="ver-line"> | </span>
        <a href="http://www.miibeian.gov.cn/" target="_blank">蜀ICP备13019762号</a>
        <script charset="utf-8" src="./无监督学习进行人脸数据降维 - 实验楼_files/v.js"></script><script src="./无监督学习进行人脸数据降维 - 实验楼_files/hm.js"></script><script type="text/javascript">
            var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
            document.write(unescape("%3Cspan id='cnzz_stat_icon_5902315'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/stat.php%3Fid%3D5902315' type='text/javascript'%3E%3C/script%3E"));
        </script><span id="cnzz_stat_icon_5902315"><a href="http://www.cnzz.com/stat/website.php?web_id=5902315" target="_blank" title="站长统计">站长统计</a></span><script src="./无监督学习进行人脸数据降维 - 实验楼_files/stat.php" type="text/javascript"></script><script src="./无监督学习进行人脸数据降维 - 实验楼_files/core.php" charset="utf-8" type="text/javascript"></script>
        <script>
            var _hmt = _hmt || [];
            (function() {
             var hm = document.createElement("script");
             hm.src = "//hm.baidu.com/hm.js?6eb47a3aeda6ea31fa53985fdfdc78e8";
             var s = document.getElementsByTagName("script")[0];
             s.parentNode.insertBefore(hm, s);
             })();
        </script>
    </div>
</div>

        
    
	

	<div class="modal fade" id="flash-message" tabindex="-1" role="dialog">
		<div class="modal-dialog" rolw="document">
		</div>
	</div>
	<div class="modal fade" id="modal-message" tabindex="-1" role="dialog" aria-hidden="true">
		<div class="modal-dialog">
			<div class="modal-content">
				<div class="modal-header">
					<button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">×</span><span class="sr-only">Close</span></button>
                    <h4 class="modal-title">注意</h4>
				</div>
				<div class="modal-body">
				</div>
				<div class="modal-footer">
                    <button type="button" class="btn btn-default" data-dismiss="modal">取消</button>
                    <button type="button" class="btn btn-primary confirm" data-dismiss="modal">确定</button>
				</div>
			</div>
		</div>
	</div>

    
<div class="modal fade" id="start-newlab">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×</button>
                <h3>开始新实验</h3>
			</div>
			<div class="modal-body">
                <p>一个实验正在进行，是否停止它，开始新实验？</p>
			</div>
			<div class="modal-footer">
                <button class="btn" data-dismiss="modal" aria-hidden="true">关闭</button>
                <a class="btn btn-primary start-newlab-confirm">确定</a>
			</div>
		</div><!-- /.modal-content -->
	</div><!-- /.modal-dialog -->
</div>
<div class="modal fade" id="start-evaluation-course">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×</button>
                <h3>开始评估课实验</h3>
			</div>
			<div class="modal-body">
                <div>
                    <p>为了让评估结果更加准确，请注意以下操作：</p>
                    <ul>
                        <li>完成实验后点击「停止实验」按钮</li>
                        <li>将代码提交到代码库</li>
                        <li>尽可能详尽的撰写实验报告</li>
                        <li>尽可能在实验操作的关键步骤截图</li>
                        <li>尽可能减少无用操作</li>
                        <li>尽可能高效的利用内存/CPU资源</li>
                    </ul>
                    <p>评估课还在不断完善中，我们真挚希望你能通过我们提供的这个平台，找到更好的发展机会。</p>
                </div>
                <br>
                <div class="start-newlab"></div>
			</div>
			<div class="modal-footer">
                <button class="btn" data-dismiss="modal" aria-hidden="true">关闭</button>
                <a class="btn btn-primary start-confirm">确定</a>
			</div>
		</div><!-- /.modal-content -->
	</div><!-- /.modal-dialog -->
</div>
<div class="modal fade" id="vip-startlab-modal">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×</button>
                <h3>开始实验</h3>
			</div>
			<div class="modal-body">
                <div class="start-newlab"></div>
                <br>
                <div class="text-center vip-vm">
                    <a class="btn btn-default btn-lg newvm">创建新环境</a>
					
                </div>
                <br>
			</div>
		</div><!-- /.modal-content -->
	</div><!-- /.modal-dialog -->
</div>


	
		
			
		
	

    

    <div id="base-data" data-flash="false" data-csrf-token="/questions/form" data-is-login="true" data-jwt-token="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzaGl5YW5sb3U6d2ViOmFwcCIsInVuYW1lIjoid2h1aGFuMjAxMyIsInVpZCI6IjIzNTcyMyIsImV4cCI6MTQ4MTQyMDk3NCwiaWF0IjoxNDgxMzM0NTc0fQ.wj6kWit4Fpd52-6szx3QuSlxqX3s1Hp5qyXvFJAx2GY" data-user-id="235723" data-is-jwt="true" data-socket-url="wss://comet.shiyanlou.com" data-msg-user="" data-msg-system=""></div>

    <script src="./无监督学习进行人脸数据降维 - 实验楼_files/lib.js"></script>
    <script src="./无监督学习进行人脸数据降维 - 实验楼_files/jquery.min.js"></script>
    <script src="./无监督学习进行人脸数据降维 - 实验楼_files/ace.js"></script>
    <script src="./无监督学习进行人脸数据降维 - 实验楼_files/aliyun-oss-sdk-4.3.0.min.js"></script>
    <script src="./无监督学习进行人脸数据降维 - 实验楼_files/highlight.min.js"></script>
    <script src="./无监督学习进行人脸数据降维 - 实验楼_files/jspdf.min.js"></script>
    <script src="./无监督学习进行人脸数据降维 - 实验楼_files/plupload.full.min.js"></script>
    <script src="./无监督学习进行人脸数据降维 - 实验楼_files/ZeroClipboard.min.js"></script>
    <script src="./无监督学习进行人脸数据降维 - 实验楼_files/video.min.js"></script>
    <script src="./无监督学习进行人脸数据降维 - 实验楼_files/bootstrap-tour.min.js"></script>
    <script src="./无监督学习进行人脸数据降维 - 实验楼_files/bootstrap-table.min.js"></script>
    <script src="./无监督学习进行人脸数据降维 - 实验楼_files/bootstrap-table-zh-CN.min.js"></script>
    <script src="./无监督学习进行人脸数据降维 - 实验楼_files/bootstrap-table-filter-control.min.js"></script>

    <script src="./无监督学习进行人脸数据降维 - 实验楼_files/raven.min.js"></script>
    <script>
    Raven.config('https://bc3878b7ed0a4468a65390bd79e6e73f@sentry.shiyanlou.com/5', {
        release: '3.11.28'
    }).install();
    </script>
    
<div id="jinja-data" data-tencent-labid="[662]" data-course-detail="/courses/707" data-left-time="0" data-course-id="707" data-userlab-id="None" data-start-newlab-url="/courses/clear"></div>
<script src="./无监督学习进行人脸数据降维 - 实验楼_files/labDoc.js"></script><div style="display: none; position: fixed; top: 0px; left: 0px; right: 0px; bottom: 0px; background: rgba(0, 0, 0, 0.498039); text-align: center; z-index: 1600;"><i class="fa fa-spinner fa-pulse" style="margin-top: 243.6px; color: rgb(255, 255, 255); font-size: 35px;"></i></div>



</body></html>